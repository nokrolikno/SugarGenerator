{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f6867d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sacremoses->transformers) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4270ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305718ae54034810ae80cc9aa113e551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8e216c33ee4658808bd4e9c31050d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b06326c42d454984d977b03f5ee0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e433514fa34cd49c3007bbff76aae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_name_or_path = 'sberbank-ai/rugpt3small_based_on_gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name_or_path).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55760756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–æ–ø—Ä–æ—Å: '–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 2+2?'\n",
      "–û—Ç–≤–µ—Ç: '2+2=4'\n"
     ]
    }
   ],
   "source": [
    "text = \"–í–æ–ø—Ä–æ—Å: '–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 2+2?'\\n–û—Ç–≤–µ—Ç:\"\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt').to(DEVICE)\n",
    "out = model.generate(input_ids, do_sample=False)\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918586f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–π –º–µ–Ω—è\n",
      "tokens:  [789, 368, 337, 848, 28306, 703]\n",
      "decoded tokens:  ['–¢', '–æ–∫', '–µ–Ω–∏', '–∑–∏', '—Ä—É–π', ' –º–µ–Ω—è']\n"
     ]
    }
   ],
   "source": [
    "text = '–¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–π –º–µ–Ω—è'\n",
    "tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in tokens]\n",
    "\n",
    "print('text: ', text)\n",
    "print('tokens: ', tokens)\n",
    "print('decoded tokens: ', decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975c04f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: \"–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å\" - —ç—Ç–æ'\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f3936a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: \"–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å\" - —ç—Ç–æ... –ß—Ç–æ —Ç–∞–∫–æ–µ \"–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å\"?<s>\n",
      "–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å ‚Äî\n"
     ]
    }
   ],
   "source": [
    "out = model.generate(input_ids,\n",
    "                     do_sample=True,\n",
    "                     top_k=20,\n",
    "                     top_p=0.8,\n",
    "                     max_length=30,\n",
    "                     temperature=0.8\n",
    "                    )\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "521b3634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b786ef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_path = 'train_dataset.txt'\n",
    "    \n",
    "train_dataset = TextDataset(tokenizer=tokenizer, file_path=train_path, block_size=64)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e03d02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1266991",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./finetuned',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=200,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=10,\n",
    "    gradient_accumulation_steps=16,\n",
    "#     no_cuda=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    optimizers=(torch.optim.AdamW(model.parameters(), lr=1e-5), None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c40d7bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 5\n",
      "  Num Epochs = 200\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 512\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:48, Epoch 200/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.02246487855911255, metrics={'train_runtime': 49.4721, 'train_samples_per_second': 20.213, 'train_steps_per_second': 4.043, 'total_flos': 32661504000000.0, 'train_loss': 0.02246487855911255, 'epoch': 200.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42d411f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in saved_model_small\\config.json\n",
      "Model weights saved in saved_model_small\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained('saved_model_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a43cb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file saved_model_small\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 2048,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading weights file saved_model_small\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at saved_model_small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('saved_model_small').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13c604db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–†—ã–±–Ω—ã–π —É–≥–∞—Ä \n",
      " \n",
      "–í–∞–∂–Ω–æ–µ —Å–ª–∞–¥–∫–æ–µ –±–ª—é–¥–æ —Å–æ–≤–µ—Ç—Å–∫–æ–π –∏ –ø–æ—Å—Ç—Å–æ–≤–µ—Ç—Å–∫–æ–π –∏—Å—Ç–æ—Ä–∏–∏. –õ–µ–≥–∫–æ–µ, –ø—ã—à–Ω–æ–µ —Ç–µ—Å—Ç–æ, –º–∞–∫—Å–∏–º—É–º —è–±–ª–æ—á–Ω–æ–π –Ω–∞—á–∏–Ω–∫–∏ ‚Äî —É —à–∞—Ä–ª–æ—Ç–∫–∏ –≤—Å–µ–≥–¥–∞ –±—ã–ª –æ–±—Ä–∞–∑ –ø—Ä–∏—è—Ç–Ω–æ–≥–æ, –ø—Ä–æ—Å—Ç–æ–≥–æ –∏ –ø—Ä–∏ —ç—Ç–æ–º –ª–∞–∫–æ–º–æ–≥–æ –∏ –¥–∏–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –±–ª—é–¥–∞. –Ø–±–ª–æ–∫–∏ –Ω–∞—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –≤–∑—è—Ç—å –∏–∑ –∫–∏—Å–ª—ã—Ö —Å–æ—Ä—Ç–æ–≤ ‚Äî –≤—Ä–æ–¥–µ –∞–Ω—Ç–æ–Ω–æ–≤–∫–∏. –ò—Ö –º–æ–∂–Ω–æ –∫–ª–∞—Å—Ç—å –∫–∞–∫ —Å—ã—Ä—ã–º–∏, —Ç–∞–∫ –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–ª–µ–≥–∫–∞ –∫–∞—Ä–∞–º–µ–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º–∏ –Ω–∞ —Å–∫–æ–≤–æ—Ä–æ–¥–∫–µ. –ò —Å–∞—Ö–∞—Ä–∞ –ª—É—á—à–µ –Ω–µ –∂–∞–ª–µ—Ç—å. –û–Ω –º–∞–≥–∏—á–µ—Å–∫–∏–º –æ–±—Ä–∞–∑–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤ –Ω—É–∂–Ω–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –≤ —Ç–µ—Å—Ç–µ, –∞ –∏–∑–ª–∏—à–∫–∏ –æ–±—Ä–∞–∑—É—é—Ç —Å–ª–∞–¥–∫—É—é –∫–æ—Ä–æ—á–∫—É.\n",
      "1. –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è —à–∞—Ä–ª–æ—Ç–∫–∞.\n",
      "–£–≥–ª–µ–∫–∏—Å–ª–æ—Ç–∞ –Ω—É–∂–Ω–∞ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ –∂–µ–ª–∞—Ç–∏–Ω–∞. –ï–≥–æ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –º–æ–ª–æ–∫–∞, —Ç–≤–æ—Ä–æ–≥–∞, –∫–µ—Ñ–∏—Ä–∞. –í—Å–µ –æ–Ω–∏ –æ–±—Ä–∞–∑—É—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ü–∏—é.\n",
      "–ñ–µ–ª—Ç–∫–∏ –≤–∑–±–∏—Ç—å —Å —Å–∞—Ö–∞—Ä–æ–º, –¥–æ–±–∞–≤–∏—Ç—å –º—É–∫—É.\n",
      "3. –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–µ —à–∞—Ä–ª–æ—Ç–∫–æ–≤–æ–µ —Ç–µ—Å—Ç–æ.\n",
      "–¢–µ—Å—Ç–æ –ø–æ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ü–∏–∏ –¥–æ–ª–∂–Ω–æ –Ω–∞–ø–æ–º–∏–Ω–∞—Ç—å —Å–º–µ—Ç–∞–Ω—É. –í—ã–ª–∏—Ç—å –ø–æ–ª–æ–≤–∏–Ω—É —Ç–µ—Å—Ç–∞ –Ω–∞ —Ä–∞–∑–æ–≥—Ä–µ—Ç—É—é —Å–∫–æ–≤–æ—Ä–æ–¥—É, –≤—ã–ª–æ–∂–∏—Ç—å –ø–æ–ª–æ–≤–∏–Ω—É –≤—Ç–æ—Ä–æ–π –ø–æ–ª–æ–≤–∏–Ω–æ–π —Ç–µ—Å—Ç–∞, —Ä–∞–∑–ª–æ–∂–∏—Ç—å —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –ø–æ–ª–æ–≤–∏–Ω—É –≤—Ç–æ—Ä–æ–π –ø–æ–ª–æ–≤–∏–Ω—ã —Ç–µ—Å—Ç–∞, –∑–∞–ª–∏—Ç—å –≤—Ç–æ—Ä–æ–π –ø–æ–ª–æ–≤–∏–Ω–æ–π –ø–µ—Ä–≤–æ–≥–æ —Ç–µ—Å—Ç–∞, –Ω–∞–∫—Ä—ã—Ç—å –≤—Ç–æ—Ä–æ–π –ø–æ–ª–æ–≤–∏–Ω–æ–π –ø–µ—Ä–≤–æ–π –ø–æ–ª–æ–≤–∏–Ω—ã –≤—Ç–æ—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞, —É–±—Ä–∞—Ç—å —Å –æ–≥–Ω—è.\n",
      "4. –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π —à–∞—Ä–ª–æ—Ç–∫–æ–≤—ã–π —à–∞—Ä–ª–æ—Ç—á–Ω—ã–π —à–∞—Ä–ª–æ—Ç–∫–æ–ë–µ—Ä–µ–º –¥–≤–µ –∫–∏—Å–ª—ã—Ö —Å–ª–∞–¥–∫–∏–µ –±—É–ª–æ—á–∫–∏ ‚Äî –ø–æ –æ–¥–Ω–æ–º—É —à—Ç—É–∫–∞–º –Ω–∞ –∫–∞–∂–¥—É—é –∏–∑ –Ω–∏—Ö. –ò—Ö –ª—É—á—à–µ –Ω–µ –∫–ª–∞—Å—Ç—å, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ —Ä–∞–∑–º–∞–∑—ã–≤–∞—é—Ç—Å—è –ø–æ –≤—Å–µ–º—É —Ç–µ—Å—Ç—É.\n",
      "–í–∑–±–∏—Ç—å –º–∏–∫—Å–µ—Ä–µ –∂–µ–ª—Ç–∫–∏, –∑–∞—Ç–µ–º –¥–æ–±–∞–≤–∏—Ç—å –º—É–∫—É, —Å–Ω–æ–≤–∞ –≤–∑–±–∏—Ç—å, –∑–∞—Ç–µ–º —Å–æ–µ–¥–∏–Ω–∏—Ç—å –∂–µ–ª—Ç–∫–∏ —Å —Å–∞—Ö–∞—Ä–æ–º.\n",
      "5. –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ —à–∞—Ä–ª–æ—Ç–Ω—ã–µ –±—É–ª–æ—á–∫–∏.\n",
      "–¢–≤–æ—Ä–æ–∂–Ω–∞—è –Ω–∞—á–∏–Ω–∫–∞ –¥–æ–ª–∂–Ω–∞ –Ω–∞–ø–æ–º–∏–Ω–∞—Ç—å —Å–º–µ—Ç–∞–Ω–∫—É. –í—ã–∂–∞—Ç—å –∏–∑ –ª–∏–º–æ–Ω–∞ —Å–æ–∫, –¥–æ–±–∞–≤–∏—Ç—å –∏–∑—é–º, –ø–µ—Ä–µ–º–µ—à–∞—Ç—å.\n",
      "6. –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏ —à–∞—Ä–ª–æ—Ç—Ç–Ω—ã–µ –±—É–ª–æ—á–∫–∏ —Å —è–±–ª–æ–∫–∞–º–∏.\n",
      "–°–º–µ—à–∞—Ç—å –≤–∑–±–∏—Ç—ã–µ —Å —Å–∞—Ö–∞—Ä–æ–º –±–µ–ª–∫–∏, –∑–∞—Ç–µ–º –ø–æ–ª–æ–≤–∏–Ω—É –º—É–∫–∏, –∑–∞—Ç–µ–º –∂–µ–ª—Ç–∫–∏. –ò—Ö –Ω—É–∂–Ω–æ —Ç—â–∞—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–º–µ—à–∞—Ç—å, —á—Ç–æ–±—ã –Ω–µ –æ–±—Ä–∞–∑–æ–≤—ã–≤–∞–ª–∏—Å—å –∫–æ–º–∫–∏. –¢–µ—Å—Ç–æ –ø–æ —Å–≤–æ–µ–º—É –≤–∫—É—Å—É –¥–æ–ª–∂–Ω–æ –Ω–∞–ø–æ–º–∏–Ω–∞—Ç—å —Ç–≤–æ—Ä–æ–≥.\n",
      "7. –ö–ª–∞—Å—Å–∏—á–µ—Å–∫—É—é —à–∞—Ä–ª–æ—Ç–∫—É.\n",
      "–†–∞–∑–ª–æ–∂–∏—Ç—å —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –ø–æ–ª–æ–≤–∏–Ω—É –Ω–∞—á–∏–Ω–∫–∏ –∏–∑ —è–±–ª–æ–∫, –∑–∞—Ç–µ–º —Ä–∞–∑–ª–æ–∂–∏—Ç—å –ø–æ–ª–æ–≤–∏–Ω—É –≤—Ç–æ—Ä–æ–π —Ç—Ä–µ—Ç–∏ —Ç–µ—Å—Ç–∞, —Å–≤–µ—Ä—Ö—É ‚Äî –≤—Ç–æ—Ä–æ–π –ø–æ–ª–æ–≤–∏–Ω–æ–π –≤—Ç–æ—Ä–æ–π –ø–æ–ª–æ–≤–∏–Ω—ã, –∑–∞–ª–∏—Ç—å –æ—Å—Ç–∞–≤—à–µ–π—Å—è –ø–æ–ª–æ–≤–∏–Ω–æ–π —Ç–µ—Å—Ç–∞ –∏ —É–±—Ä–∞—Ç—å —Å —Ä–∞–∑–æ–≥—Ä–µ—Ç–æ–≥–æ –¥–æ 180 –≥—Ä–∞–¥—É—Å–æ–≤ –º–µ—Å—Ç–µ –Ω–∞ 40 –º–∏–Ω—É—Ç.\n",
      "\n",
      "\n",
      "27327293\tpavlovskiy70\t2015-03-29 22:52:00\t–ú–æ–∏ —Ç–≤–∏—Ç—ã   –ß—Ç, 16:02\n"
     ]
    }
   ],
   "source": [
    "text = '–†—ã–±–Ω—ã–π —É–≥–∞—Ä |0| '\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt').to(DEVICE)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids,\n",
    "                        num_return_sequences=1,\n",
    "                        no_repeat_ngram_size=3,\n",
    "                        do_sample=True,\n",
    "                        num_beams=2,\n",
    "                        temperature=1.5,\n",
    "                        top_p=0.9,\n",
    "                        max_length=500,                     \n",
    "                        eos_token_id=tokenizer.eos_token_id,\n",
    "                        pad_token_id=tokenizer.pad_token_id,\n",
    "                        remove_invalid_values=True,\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "\n",
    "print(generated_text.replace('|0|', '\\n').split('<s>')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad480f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
